---
layout: post
description: "None.NULL"
tweet-text: ""
author: taocp
tags:
- programming
categories:
- ""
---


平时工作学习，常常遇到各种各样的“小问题”，有很多办法可以绕开或者“解决”，甚至忽略。有空的时候稍微深入查阅资料了解其中的原因也蛮有意思。


## Text file busy

假设可执行程序`a.out`使用了`x.so`，在`a.out`运行时，`cp a.out.new a.out`会报`Text file busy`，
`cp x.v2.so x.so`可能导致进程crash，在替换可执行文件或者动态库时，如果是先`rm`再`cp`（而不是直接`cp`覆盖）又都是ok的，为什么？

  - `rm`后再`cp`是删除旧文件（Linux保证已经打开旧文件的进程仍然能看到旧文件，这些进程都关闭旧文件时发生真正的删除）再写一个新文件（inode变了），`cp src des`是在原文件上写入新内容（inode没变）。
  - 运行时`cp a.out.new a.out`是尝试打开`a.out`写入`a.out.new`的内容，`open()`的时候Linux检测到这个二进制程序正在运行，所以返回`ETXTBSY(Text file busy)`错误。
  - 运行时`cp x.v2.so x.so`是尝试打开`x.so`写入`x.v2.so`的内容，但（截至目前2017.11）并没有针对so的“写保护”，所以覆盖写操作本身ok，不过so一般都是`mmap`到内存的，可能不是整个so文件都已在内存（按需），
    如果运行过程中替换了so，下次再访问so内容时按照旧so的各种偏移来访问新so文件就会crash.
  - [ref1](https://unix.stackexchange.com/a/74172/73846), [ref2](https://stackoverflow.com/a/7779703/1498303)


## nohup

在shell里后台执行一个任务(形如`./a.out &`)，关闭终端时，shell可能会给后台进程传送一个`SIGHUP`的信号，默认情况下收到这个信号进程就退出了。
所以，如果是简单的`a.out &`后台执行一个程序，可能不小心退出终端（毕竟高兴的时候一口气N个`exit`根本停不下来）或者断网就会导致任务中断。

原因清楚以后，要解决这个问题就有好几种办法了。

- 配置一下，使得shell收到`SIGHUP`以后，不再发送给它的子进程。例如bash可以通过`shopt -s huponexit`和`shopt -u huponexit`来控制，`shopt huponexit`获取当前配置。我遇到的好些Linux环境，bash默认都是`huponexit off`的，也就是默认情况下退出终端不会kill掉后台进程。

- GNU的`nohup`工具，它在`coreutils`（GNU core utilities）里，看看源码就会发现原理挺直白的，先`signal (SIGHUP, SIG_IGN);`然后`exec()`从而忽略掉`SIGHUP`。

- [signal-wiki](https://en.wikipedia.org/wiki/Signal_(IPC)), [sighup-wiki](https://en.wikipedia.org/wiki/SIGHUP), [ref3](https://serverfault.com/a/117157/294205), [ref4](https://stackoverflow.com/a/4319666/1498303), nohup-src


## 编码问题

(TODO)

<!-- 原理说明；实验：终端编码、vim编码配置、文件编码 -->


- [unicode at joelonsoftware]( https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses)
- [unicode in python](http://farmdev.com/talks/unicode/)


## mmap

[mmap](https://en.wikipedia.org/wiki/Mmap) 如何使用，有太多资料可以参考。内部大概是怎样的工作原理，看看wiki/man会有个基本的认识（一般情况来说应该够用了，有需要可以看看内核的实现？）。这里说说相较于 read()/write() 它有哪些优势。

准确地说，应该是拿 mmap() + 指针操作 和 read()/write() 比较，mmap()本身并不访问磁盘，通过它返回的指针访问内存等效于 read()/write() .

首先，我认为最重要是，mmap()以后可以把文件当作内存，用指针来操作，在有些情况下，可以极大简化程序。减轻人的负担，是最重要的。

然后，是性能上的优势。

  - mmap()相较于 read()/write() 减少了一次内存拷贝。数据从磁盘到mmap区域只有1次拷贝；read()会从磁盘到内核，再从内核到用户程序，有2次。
  - mmap()减少了read()/write()系统调用、上下文切换的开销。
  - mmap()支持多进程共享同一块内存映射，这种情况下，既减少了IO，又节省了内存。

《性能之巅》在性能方面讨论得更深入。

我观察到，部分程序员对mmap()存在某种误解，认为操作mmap()返回的指针，既能有访问内存那样的效率，又能像磁盘那样可靠（` mmap_ptr[0]='c' `执行完数据就已经落在磁盘了，断电也不会有损失）。
天下怎么会有这等好事？如果真有，那么 mmap() 应该已经把 read()/write() 扫进历史的垃圾堆了。而且， write() 需要调用 fsync() 才能保证数据落盘，同理 mmap() 需要 msync() 。

说回性能，mmap() 和 read()/write() 各自的实现决定了，不同场景性能表现会不同，所以，需要的话还是测试一下更靠谱。

一个比较典型的例子是：一个大文件，持续地随机访问场景，用mmap()会比较有利。

如果物理内存足够存下这个大文件，那么这个文件的任一块被随机IO 1次 映射到内存以后，后续就不会有随机IO了。（不考虑内核写回的场景）。

而用 read() 随机读，即便文件的每一块都曾经被读过，也不能保证后续每次访问都命中 Page Cache 或者磁盘自己的cache。
持续地随机访问一个大文件场景，Page Cache很难一直把整个文件（的每一块内容）都cache着，例如还有其它IO操作竞争Page Cache.
如果期间随机访问的频率还比较高，那系统调用、上下文切换和内存拷贝的开销也值得关注。


参考资料：

《性能之巅》第八章 文件系统

*Advanced Programming in the UNIX® Environment*, 3e, ch. 14 advanced I/O

*Linux System Programming*, 2e, ch.4 advanced file I/O

*The Linux Programming Interface*, ch.49 memory mapping

Wiki [https://en.wikipedia.org/wiki/Mmap](https://en.wikipedia.org/wiki/Mmap)


## 为什么有的C++代码在遍历STL容器时，迭代器的用法是"++it"而不是"it++"？

例如 [cppreference.com std::map::begin()](https://en.cppreference.com/w/cpp/container/map/begin)  的示例代码。
遍历 std::map 时，迭代器的用法是"++it".
很多优秀的C++开源项目里，也是如此。

**主要原因是性能**。

"i++"的实现是先 old_i = i; i += 1; 然后返回 i 的旧值；
 "++i"的实现是先 i +=1; 然后返回 i 的引用。
postfix比prefix多了一次拷贝。

[cppreference.com operator_incdec](https://en.cppreference.com/w/cpp/language/operator_incdec) 对此有些说明。

参考[increment-and-decrement-operator-overloading-cpp](https://docs.microsoft.com/en-us/cpp/cpp/increment-and-decrement-operator-overloading-cpp) 自己实现重载了prefix/postfix的++/--, 可能更直观、详细一些。

[C++ 17 标准](https://github.com/cplusplus/draft/blob/c%2B%2B17/papers/n4659.pdf)有权威说明。 *8.2.6 Increment and decrement*  &  *8.3.2 Increment and decrement*

部分情况下，编译器可能足够聪明，可以将"i++"优化为"++i"。不过，依赖这么一个标准未明确定义的行为，并不明智。而且自定义类型重载++/--的情况，优化起来有一定难度？鉴于用键盘敲下"++it"和"it++"代价一样，以及（特别是）二者可读性几乎没有差别，那选择 prefix的"++it"至少不差于 postfix的"it++".
网上有些[博客](https://www.viva64.com/en/b/0093/)的测试显示，部分情况下，prefix明显好于postfix. 我觉得不用纠结，实现和维护A/B的代价一样，A(prefix)的效果不差于B(postfix)，那不用纠结直接选A(prefix)就好了啊，省去很多选择的烦恼了。

“普通”的for循环中，通常沿用"i++"的原因，我猜主要还是习惯问题。 int 拷贝的代价比较小，而且编译器更容易优化，一般这里也不会成为瓶颈，那就遵从习惯吧。

stackoverflow上的[这个讨论](https://stackoverflow.com/questions/24901/is-there-a-performance-difference-between-i-and-i-in-c)，也可以围观下。

有几点值得注意的：

1. C++支持重载prefix/postfix的++/--，作为实现者要注意和经典行为保持一致；作为用户注意别被不靠谱的重载实现给坑了。

2. 这点上，C和C++不一样。可以参考[这个问题](https://stackoverflow.com/questions/21351799/postfix-prefix-increment-l-value-and-r-value-in-c-and-c).


## rsync

1. rsync在什么场景下更能发挥其优势？
2. rsync的基本原理？

参考：

[https://en.wikipedia.org/wiki/Rsync](https://en.wikipedia.org/wiki/Rsync)

[https://rsync.samba.org/how-rsync-works.html](https://rsync.samba.org/how-rsync-works.html)

[https://www.quora.com/How-does-the-rsync-algorithm-work](https://www.quora.com/How-does-the-rsync-algorithm-work)


## snprintf

man手册原文里的说法有部分人不太能很快理清，换个我的说法：

`int snprintf(char *str, size_t size, const char *format, ...);`

简单来说，snprintf会自动在末尾添加'\0'，而且最多写@size个字符（包括'\0'在内）。

如果目的buffer大小足够，那么返回值即为写入字符的数量（不包括'\0'）；
如果目的buffer大小不够，那么返回值为预期想要写入字符的数量（不包括'\0'）。

如果传入参数为size，那么最多可以写 （size-1个字符 + 末尾的'\0' = ）size个字符，此时返回值为 n-1.
因此，如果返回值ret >= size，说明size偏小，写入的内容被截断了。

权威参考`man snprintf`，可以仔细读读。